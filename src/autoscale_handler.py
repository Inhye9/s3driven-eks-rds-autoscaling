import json
import urllib.parse
import boto3
import csv
import logging
import urllib3
import os
import time
from zoneinfo import ZoneInfo
from datetime import datetime, timedelta 
from botocore.exceptions import WaiterError 


scheduler = boto3.client('scheduler')
ec2_client = boto3.client('ec2')
ssm_client = boto3.client('ssm')
s3 = boto3.client('s3')

lambda_name = 'autoscale_handler.py'
instance_id = '' # kubectl ec2 id 
scheduler_prefix = 'autorun'
osuser = 'appuser'  # kubectl ec2 app os id

# í˜„ì¬ ì¼ì 
#today_date  = datetime.now().date()
# print(today_date.strftime("%Yë…„ %mì›” %dì¼"))

zonetz = ZoneInfo("Asia/Seoul")
today_date=datetime.now(tz=zonetz)
print(today_date.strftime("%Yë…„ %mì›” %dì¼"))

# loading ë¡œê·¸ 
logging.warning('********************************************************************************')
logging.warning('[START] ' + lambda_name + ' is loading.')

# boto3ë¡œ s3 triggerì˜ dataë¥¼ received
def lambda_handler(event, context):
    
    # start ë¡œê·¸ 
    write_log(1,'')
    print("Received event: " + json.dumps(event, indent=2))

    # Teamsë¡œ ë³´ë‚¼ ê²°ê³¼ê°’ ë³€ìˆ˜
    result_code = 200
    result_msg = ""
    parsed_str = ""
    key = ""
    
    try:
        # eventì—ì„œ bucketê³¼ key ì¶”ì¶œ
        bucket = event['Records'][0]['s3']['bucket']['name']
        key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')
        
        response = s3.get_object(Bucket=bucket, Key=key)
        logging.warning("[INFO] key: " + key)

        # csv íŒŒì¼ëª…ì´ ë§ìœ¼ë©´ ìˆ˜í–‰
        if not 'autorun' in key :
          # raise("[Error] The file is not right. Upload autorun-sms.csv on s3://pri-autorun-sms-s3/update_schedule/")
          print("[Error] The file is not right. Upload autorun-sms.csv on s3://pri-autorun-sms-s3/update_schedule/")
          return 
            
        # Bodyë¥¼ lineìœ¼ë¡œ split í•¨.
        res_body = response.get('Body').read().splitlines() 
        
        # responseì˜ Bodyê°’: Byte -> ë¬¸ìì—´ í˜•íƒœë¡œ ë³€í™˜.
        # resList = [x.decode(encoding = 'utf-8') for x in resBody ]
        res_list = [x.decode(encoding = 'cp949') for x in res_body ]

        # responseì˜ Bodyê°’: ë¬¸ìì—´ -> ë°°ì—´ í˜•íƒœë¡œ ë³€í™˜
        parsed_data, parsed_str = parse_csv(res_list)
        
        # parsed_dataë¥¼ cron ë“±ë¡ì„ ìœ„í•œ í˜•íƒœë¡œ ë³€í™˜
        cronjob = convert_to_crontab_format(parsed_data)
        
        # cronì„ workbenchì— ì—…ë¡œë“œ 
        upload_crontab_on_ec2(cronjob)
        
        # eventbridge_schedulerë¥¼ ë“±ë¡ 
        generate_eventbridge_scheduler(parsed_data)

        
    # return response['ContentType']
    except Exception as e:
        #logging.error(e)
        #logging.error('[Error] getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.'.format(key, bucket))
        result_code = 500
        #result_msg = json.dumps(e).encode('utf-8')
        result_msg+='[Error] ' + str(e)
        logging.error(result_msg)
    # raise e
    
    try:
        # ê²°ê³¼ê°’ì„ SNSë¥¼ í™œìš©í•˜ì—¬ Teamsë¡œ ë©”ì„¸ì§€ ì „ì†¡
        send_result_to_teams(result_code, result_msg, parsed_str, key)
        
    except Exception as e:   
        logging.error(e)
    
    # done ë¡œê·¸ 
        write_log(2,'')
        logging.warning('********************************************************************************')

## parse_csv: csvë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
# ì˜ˆ) 2024,4,2,12,00,13,00 = 2024ë…„ 4ì›” 2ì¼ 12:00-13:00 
def parse_csv(res_list): 
    parsed_data = [] 
    parsed_str = ""
    
    # ì½¤ë§ˆ(,)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ csvë¥¼ íŒŒì‹±. 
    csv_list = csv.reader(res_list, delimiter=',', quotechar='"')
    for idx, row in enumerate(csv_list):
        # idx == 0ì€ csvì˜ titleì´ë¯€ë¡œ ìƒëµí•œë‹¤. 
        if idx == 0:
            continue
        
        if (len(row) < 12) or (len(row) > 14): 
            raise ValueError('[Error] The file on s3 bucket is wrong. The column of File does not match. len(row):' + str(len(row)) +"/14")
        
        event_db = ''
        # event DB ì¦ì„¤ì—¬ë¶€ ì„¸íŒ…
        if row[10] != '':
            event_db = str(row[10]).replace(' ','') 
            event_db = event_db.upper()
        else:
            event_db = "N"
        
        # percentage ì„¸íŒ… 
        if row[11] == '':
            row[11] = 100
        
        # start_timeì´ í˜„ì¬ ì‹œê°„ ì´ì „ -> ìƒëµ(ì¦ì„¤x)
        start_time = datetime(int(row[0]), int(row[1]), int(row[2]), int(row[3]), int(row[4]))
        outdated = check_outdated(start_time)
     
        if not outdated: 
            parsed_data.append({
                'start_year': int(row[0]),
                'start_month': int(row[1]),
                'start_day': int(row[2]),
                'start_hour': int(row[3]),
                'start_minute': int(row[4]),
                'end_year': int(row[5]),
                'end_month': int(row[6]),
                'end_day': int(row[7]),
                'end_hour': int(row[8]),
                'end_minute': int(row[9]),
                'event_db': event_db,  #Y/N
                'percentage': int(row[11]),
                'title': str(row[12]),
                'register': str(row[13])
            })
        
        # teams ì¶œë ¥ ë©”ì„¸ì§€ ì„¸íŒ…
        # register ì—¬ë¶€ í™•ì¸ 
        if str(row[13]) != '':
            parsed_str += "<br>ğŸ“Œ <b>" + str(row[12]) + "/" + str(row[13]) +"</b>\n"
        else: 
            parsed_str += "<br>ğŸ“Œ <b>" + str(row[12]) + "</b>\n"
        
        parsed_str += "<br>" + "&nbsp;&nbsp;â— " +str(row[0])+"ë…„ "+str(row[1])+"ì›” "+str(row[2])+"ì¼ "+str(row[3])+"ì‹œ "+str(row[4])+"ë¶„ ~ "
        parsed_str += str(row[5])+"ë…„ "+str(row[6])+"ì›” "+str(row[7])+"ì¼ "+str(row[8])+"ì‹œ "+str(row[9])+"ë¶„ "
        
        # # percentage í™•ì¸
        # if int(row[11]) == -1:
        #     parsed_str += ",ì¦ì„¤ ìˆ˜ëŸ‰: Fixed, EventDB ì¦ì„¤: "+ str(event_db) + "\n<br>"   
        # else:
        #     parsed_str += ",ì¦ì„¤ ìˆ˜ëŸ‰: "+ str(row[11]) +"%, EventDB ì¦ì„¤: "+ str(event_db) + "\n<br>"   
        
        # percentage í™•ì¸
        if int(row[11]) == -1 and not outdated:
            parsed_str += ",ì¦ì„¤ ìˆ˜ëŸ‰: Fixed, EventDB ì¦ì„¤: "+ str(event_db) + "\n<br>"   
        elif outdated: 
            parsed_str += ",ì¦ì„¤ ìˆ˜ëŸ‰: X(ì§€ë‚œ ì¼ì), EventDB ì¦ì„¤: "+ str(event_db) + "\n<br>"   
        else:
            parsed_str += ",ì¦ì„¤ ìˆ˜ëŸ‰: "+ str(row[11]) +"%, EventDB ì¦ì„¤: "+ str(event_db) + "\n<br>" 
    
    
    # done ë¡œê·¸ 
    write_log(0,'parse_csv')
    return parsed_data, parsed_str; 


## convert_to_crontab_format: parsed_dataë¥¼ crontab í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” í•¨ìˆ˜
def convert_to_crontab_format(parsed_data): 
    #cronjobs = []
    cronjob = ""
    homepath = "/apps/operating-itn"
    logpath = homepath + "/logs/cron_autorun.log 2>&1"
    
    for event in parsed_data:
        start_time = datetime(event['start_year'], event['start_month'], event['start_day'], event['start_hour'], event['start_minute'])
        end_time = datetime(event['end_year'], event['end_month'], event['end_day'], event['end_hour'], event['end_minute'])
        
        p = event['percentage']
        
        # skip
        if p == -1:  
            continue
        
        # ë”ë¸”ë§ˆì¼ë¦¬ì§€ í–‰ì‚¬ì˜ ê²½ìš°(3/13, 14, 15, 16):
        d_year = start_time.year
        d_month = start_time.month
        d_day = start_time.day

        # ìˆ˜ìš”ì¼ ì•„ìš¸ë › í–‰ì‚¬ì˜ ê²½ìš°
        start_weekday = start_time.weekday()
        if start_weekday == 2: 
            if p > 50:
                cronjob += (start_time - timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh max >> " + logpath + " #autoreg" + "\n"
                cronjob += (end_time + timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh half >> " + logpath + " #autoreg" + "\n"
            else: 
                continue
        # ë”ë¸”ë§ˆì¼ë¦¬ì§€ í–‰ì‚¬ì˜ ê²½ìš°(3/13, 14, 15, 16):
        elif d_year == 2025 and d_month == 3 and d_day in {13, 14, 15, 16}:
                if p > 50:
                    cronjob += (start_time - timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh max >> " + logpath + " #autoreg" + "\n"
                    cronjob += (end_time + timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh half >> " + logpath + " #autoreg" + "\n"
                else: 
                    continue
        # ë‹¤ë¥¸ ìš”ì¼ì˜ ê²½ìš°(ìˆ˜ ì œì™¸)
        else: 
            if p > 50:
                cronjob += (start_time - timedelta(minutes=40)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh half >> " + logpath + " #autoreg" +"" "\n"
                cronjob += (start_time - timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh max >> " + logpath + " #autoreg" + "\n"
                cronjob += (end_time + timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh half >> " + logpath + " #autoreg" + "\n"
                cronjob += (end_time + timedelta(minutes=40)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh min >> " + logpath + " #autoreg" + "\n"
            elif 25 < p <= 50 :
                cronjob += (start_time - timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh half >> " + logpath + " #autoreg" + "\n"
                cronjob += (end_time + timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh min >> " + logpath + " #autoreg" + "\n"
            else :
                cronjob += (start_time - timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh quarter >> " + logpath + " #autoreg" + "\n"
                cronjob += (end_time + timedelta(minutes=30)).strftime('%M %H %d %m *')+ osuser + homepath +"/bin/cron_autorun.sh min >> " + logpath + " #autoreg" + "\n"
        
    
    # done ë¡œê·¸ 
    write_log(0,'convert_to_crontab_format')
    return cronjob


## upload cronFile on workbench EC2: cronjob ë¦¬ìŠ¤íŠ¸ë¥¼ EC2ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
def upload_crontab_on_ec2(cronjob):
    
    # ec-tagëª…ìœ¼ë¡œ ec2ì˜ instance_idë¥¼ ê°€ì ¸ì˜¨ë‹¤
    response = ec2_client.describe_instances(
        Filters=[
            {
                'Name': 'tag:Name',
                'Values': ['workbench-ec2'] # workbench-ec2
            }
        ]
    )
    instance_id = response['Reservations'][0]['Instances'][0]['InstanceId']
    print("instance_id:" + str(instance_id))
    
    # ssmì„ ì‚¬ìš©í•´ì„œ ec2ì˜ instanceì— ëª…ë ¹ ì „ì†¡ 
    # init_crontab.sh: csv ë“±ë¡ì¼ì ê¸°ì¤€ ì´ì „ cronì„ ì‚­ì œí•˜ëŠ” shell
    #exec_shell_path = "/root/workspace/chart/bin"
    exec_shell_path = "/apps/operating-itn/bin"
    response = ssm_client.send_command(
        InstanceIds=[instance_id],
        DocumentName="AWS-RunShellScript",
        TimeoutSeconds=60,
        Parameters={
            'commands': [
                #f"echo '{cronjob}' | sudo tee -a /etc/crontab"
                #f"sudo /root/workspace/chart/bin/init_crontab.sh && echo '{cronjob}' | sudo tee -a /etc/crontab"
                #f"sudo '{exec_shell_path}'/init_crontab.sh && echo '{cronjob}' | sudo tee -a /etc/crontab"
                f"sudo /apps/operating-itn/bin/init_crontab.sh  && echo -n '{cronjob}' | sudo tee -a /etc/crontab" 
            ]
        }
    )
    
     # ëª…ë ¹ì–´ ì‹¤í–‰ ìƒíƒœë¥¼ í™•ì¸ 
    invoCnt = 3
    while 0 < invoCnt < 4 :
        time.sleep(1)  # API í˜¸ì¶œ ì‚¬ì´ì— ê°„ê²©ì„ ë‘ì–´ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œê°„ì„ ë³´ì¥
        invoCnt-=1
        
        # ëª…ë ¹ì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œ
        output = ssm_client.get_command_invocation(
            CommandId=response['Command']['CommandId'],
            InstanceId=instance_id
        )
        status = output['Status'].lower()
        print("inVoCnt:" + str(invoCnt) +", status:" + status)
        
        if status in ['pending', 'inprogress']:
            if invoCnt == 1 : 
                print("upload_crontab_on_ec2.response =" + json.dumps(output, default=str, indent=2))
                raise('[Error] SSM Client failed to load the command to the instance['+instance_id+'] in 3s')
            else:
                continue
        elif status == 'success':
            return
        else:
            print("upload_crontab_on_ec2.response =" + json.dumps(output, default=str, indent=2))
            raise('[Error] SSM Client failed to load the command to the instance['+instance_id+'] in 3s')

    
    # send_commandë¡œ ì „ì†¡í•œ command ì‹¤í–‰ ì¢…ë£Œë¥¼ wait
    #print("upload_crontab_on_ec2.response =" + json.dumps(response, default=str, indent=2))

    #if str(response['ResponseMetadata']['HTTPStatusCode']) != '200':
    #  raise('[Error] SSM Client failed to load the command to the instance['+instance_id+']')
    
    # done ë¡œê·¸ 
    write_log(0,'upload_crontab_on_ec2')
    
    
## generate_eventbridge_scheduler: eventbridge schedulerë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_eventbridge_scheduler(parsed_data):
    
    # csv ë“±ë¡ì¼ì ê¸°ì¤€ ì´ì „ EventBridge schedulerë¥¼ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜
    delete_previous_eventbridge_scheduler()
    
   
    
    # ìƒˆë¡œìš´ EventBridge schedulerë¥¼ ë“±ë¡ 
    for idx, event in enumerate(parsed_data):
        start_time = datetime(event['start_year'], event['start_month'], event['start_day'], event['start_hour'], event['start_minute'])
        end_time = datetime(event['end_year'], event['end_month'], event['end_day'], event['end_hour'], event['end_minute'])
        
        #Scheduler ì‹œê°„ ì‚°ì¶œ
        date = start_time.strftime('%Y%m%d-%H')
        add_time_1 = (start_time - timedelta(minutes=60)).strftime('%Y-%m-%dT%H:%M:%S')
        add_time_2 = (start_time - timedelta(minutes=50)).strftime('%Y-%m-%dT%H:%M:%S')
        del_time_1 = (end_time + timedelta(minutes=50)).strftime('%Y-%m-%dT%H:%M:%S')
        del_time_2 = (end_time + timedelta(minutes=60)).strftime('%Y-%m-%dT%H:%M:%S')
        
        
        # ë³€ìˆ˜ ì„¸íŒ… 
        action=""
        time=""
        dbname=""
        dbtype=""
        
        # x: ì¦ì„¤ìˆ˜ëŸ‰ ì„¤ì •, y: eventDB ì¦ì„¤ ì—¬ë¶€ ì„¤ì • 
        y=1 
        x=0
        
        # skip 
        if int(event['percentage']) == -1: # skip 
            continue

        # '25.03.10 ì¶”ê°€> ë”ë¸”ë§ˆì¼ë¦¬ì§€ í–‰ì‚¬ì˜ ê²½ìš°(3/13, 14, 15, 16):
        d_year = start_time.year
        d_month = start_time.month
        d_day = start_time.day

        
        # ìˆ˜ìš”ì¼ ì•„ìš¸ë › í–‰ì‚¬ì˜ ê²½ìš°: 
        start_weekday = start_time.weekday()
        if start_weekday == 2:
            if int(event['percentage']) > 50:  # RDS 1ê°œë§Œ ì¦ì„¤ 
                x=3
            else: 
                x=1  # skip
                 
            if event['event_db'] == "Y":
                y=3
            else:
                y=2
        # '25.03.10 ì¶”ê°€> ë”ë¸”ë§ˆì¼ë¦¬ì§€ í–‰ì‚¬ì˜ ê²½ìš°(3/13, 14, 15, 16):
        elif d_year == 2025 and d_month == 3 and d_day in {13, 14, 15, 16}:
            if int(event['percentage']) > 50:  # RDS 1ê°œë§Œ ì¦ì„¤ 
                x=3
            else: 
                x=1  # skip
                 
            if event['event_db'] == "Y":
                y=3
            else:
                y=2
        # ìˆ˜ìš”ì¼ì´ ì•„ë‹Œ ê²½ìš° 
        else:
            if int(event['percentage']) > 50:
              x=5 
            else:
              x=3
        
            if event['event_db'] == "Y":
              y=3
            else: 
              y=2 
        
        # schedulerëŠ” ì„¤ì • ì‹œê°„ 1ê°œë‹¹ 4ê°œ scheduler ë“±ë¡(2ê°œì˜ add, 2ê°œì˜ remove)
        for j in range(1, y):
            if j == 1:
                dbname = "order"
                dbtype = "db.r5.4xlarge"
            elif j == 2: 
                dbname = "event" 
                dbtype = "db.r5.2xlarge"
                    
            for i in range(1, x):
                if i == 1: 
                    action = "add"
                    time = add_time_2
                if i == 2: 
                    action = "remove"
                    time = del_time_1
                if i == 3: 
                    action = "add"
                    time = add_time_1
                if i == 4: 
                    action = "remove"
                    time = del_time_2
            
                schedule_name = scheduler_prefix + dbname +'-read-'+ date + '-' + action +'-'+str(i)
                          
                # scheduler_targetì„ ì„¤ì •
                scheduler_target = {
                                # Lambda ì„¤ì •: autorun-managing-rds-reader-lmb
                                'Arn' : 'arn:aws:lambda:ap-northeast-2:206178055504:function:autorun-managing-rds-reader-lmb', 
                                # Role ì„¤ì •: autorun-managing-rds-reader-schedule-role
                                #'RoleArn': 'arn:aws:iam::206178055504:role/autorun-managing-rds-reader-schedule-role',
                                'RoleArn': 'arn:aws:iam::206178055504:role/service-role/autorun-managing-rds-reader-schedule-role',
                                # Payload ì„¤ì •
                                'Input': json.dumps({
                                    "identifier" : scheduler_prefix +dbname+"-cluster", 
                                    "action" : action, 
                                    "db_type" : dbtype, 
                                    "quantity" : "1"  
                                }),
                                # RetryPolicy: OFFë¡œ ì„¤ì •
                                'RetryPolicy': {
                                    'MaximumEventAgeInSeconds': 60,
                                    'MaximumRetryAttempts': 0
                                }
                }
            
                try: 
                # evenbridge scheduler ë¥¼ ìƒì„±í•œë‹¤.
                    response = scheduler.create_schedule(
                        #Name = date +'-'+str(i) + '-autorun-order-read-'+ action , 
                        Name = schedule_name, 
                        GroupName = 'autorun-managing-rds-reader-sg',
                        ScheduleExpression = 'at('+time+')',
                        ScheduleExpressionTimezone = 'Asia/Seoul', 
                        FlexibleTimeWindow = {"Mode":"OFF"},
                        Target = scheduler_target,
                        State= 'ENABLED', #DISABLED/ENABLED
                        ActionAfterCompletion = 'NONE',
                    )        
            
                except Exception as e:
                    error_msg = str(e)
                    print(str(e))
                    if (schedule_name + ' already exists' in error_msg):
                        logging.warning ('[Warning] '+ schedule_name + ' already exists.' )
                        continue
                    else:
                        raise(error_msg)
                
    # done ë¡œê·¸ 
    write_log(0,'generate_eventbridge_scheduler')

                
# delete_previous_eventbridge_scheduler: ì´ì „ EventBridge Schedulerë¥¼ ì „ì²´ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜
def delete_previous_eventbridge_scheduler():
    
    # ê¸°ì¡´ scheduler ëª©ë¡ ì¡°íšŒ(ìŠ¤ì¼€ì¤„ëŸ¬ëª…: autorun-order-read*)
    response = scheduler.list_schedules(
        GroupName = 'autorun-managing-rds-reader-sg',
        NamePrefix = 'autorun-'
    )
    
    
    # ì‚­ì œí•  scheduler ìˆëŠ” ì§€ ì²´í¬
    if not response['Schedules']:
        logging.warning('There is no previous schedule to delete in response.')
        return 
    
    # ì§€ë‚œ scheduler ì „ì²´ ì‚­ì œ 
    scheduler_name_list = [sche ['Name'] for sche in response['Schedules']]
    for name in scheduler_name_list:

        # Eventbridge scheduler ì „ì²´ ì‚­ì œ
        response = scheduler.delete_schedule(
            #GroupName = 'autorun-managing-rds-reader-sg',
            GroupName = 'autorun-managing-rds-reader-sg',
            Name = name
        )
        
        # print('delete response:' +json.dumps(response, default=str, indent=2))
        if str(response['ResponseMetadata']['HTTPStatusCode']) != '200':
            raise('[Error] EventBridge Scheduler " + name + " was not deleted.')
    
    # done ë¡œê·¸ 
    write_log(0, 'delete_previous_eventbridge_scheduler')
    

# write_log: logë¥¼ write í•´ì£¼ëŠ” í•¨ìˆ˜
def write_log(num, function_name): 
    # 0 = done 
    if num == 0:
        logging.warning('[DONE] ' + lambda_name + '.' + function_name +' was done.')
    # 1 = start
    elif num == 1:
        logging.warning('[START] ' + lambda_name + ' is starting.')
    # 2 = finish(ì™„ì „ ì¢…ë£Œ) 
    elif num == 2: 
        logging.warning('[DONE]' + lambda_name + ' was successfully done. ')
    else:
        return
        

# send_result_to_teams(): ê²°ê³¼ë¥¼ SNSì„ í†µí•˜ì—¬ Teams Webhookìœ¼ë¡œ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜ 
def send_result_to_teams(result_code, result_msg, parsed_str, key):
    # ìš”ì¼ë³„ emoji ê°€ì ¸ì˜¤ê¸°
    emoji, weekday = get_weekday_emoji()
    
    if result_code == 200:
        result_flag = emoji + "âœ… [ìŠ¤ì¼€ì¤„ ë“±ë¡ ì™„ë£Œ] <b>" +  today_date.strftime("%Yë…„ %mì›” %dì¼") + "("+ weekday +") </b>ì— ë“±ë¡ëœ ìŠ¤ì¼€ì¤„ ëª©ë¡ì…ë‹ˆë‹¤.  <br><br>"
        # result_flag = "âœ… [ìŠ¤ì¼€ì¤„ ë“±ë¡ ì™„ë£Œ] on " + key +"\n"
        # result_msg = "The requested schedules have been registered successfully.<br>"
        result_msg = " "
    else: 
        result_flag = emoji + "ğŸ’¥[ìŠ¤ì¼€ì¤„ ë“±ë¡ ì‹¤íŒ¨] on" + key +"\n"
        
    # ì „ì†¡í•  ë©”ì„¸ì§€ ì²˜ë¦¬
    msg = {
        'text': result_flag + "\n" + result_msg + "\n" + parsed_str
    }
    
    # urllib3ìœ¼ë¡œ http ì—°ê²° ì²˜ë¦¬ 
    http = urllib3.PoolManager()
    # teams webhookì„ ê°€ì ¸ì˜¨ë‹¤(Lambda>êµ¬ì„±>í™˜ê²½ë³€ìˆ˜*)
    url = os.environ['teams_webhook']
    
    # msgë¥¼ teams webhookìœ¼ë¡œ ì „ì†¡
    encoded_msg = json.dumps(msg).encode('utf-8')
    resp = http.request('POST',url, body=encoded_msg)

    
    # done ë¡œê·¸ 
    write_log(0, 'send_result_to_teams')

# í˜„ì¬ì‹œê°„ ì¼ìì™€ input(datetime) ë¹„êµ    
def check_outdated(date_in):
    today_date = datetime.now()
    
    return today_date > date_in
## /etc/crontab init_cron.sh í•„ìš”

def get_weekday_emoji():
    weekday = today_date.weekday()
    
    weekday_emojis = {
    0: "ğŸŒ",
    1: "ğŸš€",
    2: "ğŸ‘š",
    3: "ğŸ“º",
    4: "ğŸ™‰",
    5: "ğŸ˜",
    6: "ğŸ„"
    }
    
    weekday_kor = {
    0: "ì›”",
    1: "í™”",
    2: "ìˆ˜",
    3: "ëª©",
    4: "ê¸ˆ",
    5: "í† ",
    6: "ì¼"
    }
    
    return weekday_emojis[weekday], weekday_kor[weekday] 